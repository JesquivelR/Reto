# ğŸ› ï¸ ResoluciÃ³n del Reto TÃ©cnico

## ğŸ“‹ DescripciÃ³n del Proyecto

DiseÃ±ar y desplegar una infraestructura escalable, segura y de alta disponibilidad en AWS que soporte aplicaciones modernas basadas en contenedores, utilizando servicios como ECS Fargate, NAT Gateway y Application Load Balancer (ALB), Lambda y EventBridge.

---

## ğŸ”§ TecnologÃ­as Usadas
1. **Terraform:** Herramienta IaC para definir y desplegar infraestructura.
2. **AWS:**
    - ``IAM``: Servicio de gestiÃ³n de identidades y acceso en AWS para controlar el acceso a recursos.
    
    - ``S3``: Servicio de almacenamiento de objetos altamente escalable y duradero.
    
    - ``DynamoDB``: Base de datos NoSQL totalmente gestionada, rÃ¡pida y flexible.
    
    - ``ECR``: Registro de contenedores para almacenar, administrar y desplegar imÃ¡genes Docker.
    
    - ``ECS``: Servicio de contenedores de Amazon para ejecutar aplicaciones en contenedores en AWS.
    
    - ``CloudWatch``: Servicio de monitoreo que proporciona mÃ©tricas y logs de recursos en AWS.
    
    - ``Fargate``: Motor de computaciÃ³n sin servidor para ejecutar contenedores en ECS y EKS sin gestionar servidores.
    
    - ``Security Groups``: Conjunto de reglas de firewall para controlar el trÃ¡fico de red hacia las instancias de AWS.
    
    - ``ALB``: Balanceador de carga de aplicaciones para distribuir trÃ¡fico a aplicaciones dentro de AWS.

    - ``EventBridge``: Programador sin servidor que facilita la creaciÃ³n, ejecuciÃ³n y administraciÃ³n de tareas programadas a escala..

    - ``Lambda``: Ejecuta cÃ³digo en respuesta a eventos y administra los recursos informÃ¡ticos.

3. **GitHub Actions:** Plataforma de integraciÃ³n y despliegue continuos (CI/CD) que permite automatizar el desarrollo de software.

4. **Docker:** Plataforma para desarrollar, enviar y ejecutar aplicaciones en contenedores, garantizando consistencia y portabilidad.

---

## ğŸ“‹ Estructura del Proyecto

### 1. Arbol de directorios

```bash
.
â””â”€â”€ <Root>
    â”œâ”€â”€ app1
    â”‚Â Â  â”œâ”€â”€ Dockerfile
    â”‚Â Â  â”œâ”€â”€ main.py
    â”‚Â Â  â””â”€â”€ requirements.txt
    â”œâ”€â”€ app2
    â”‚Â Â  â”œâ”€â”€ Dockerfile
    â”‚Â Â  â”œâ”€â”€ main.py
    â”‚Â Â  â””â”€â”€ requirements.txt
    â””â”€â”€ terraform
        â”œâ”€â”€ environments
        â”‚Â Â  â”œâ”€â”€ dev
        â”‚Â Â  â”‚Â Â  â”œâ”€â”€ backend.tf
        â”‚Â Â  â”‚Â Â  â”œâ”€â”€ main.tf
        â”‚Â Â  â”‚Â Â  â”œâ”€â”€ outputs.tf
        â”‚Â Â  â”‚Â Â  â””â”€â”€ variables.tf
        â”‚Â Â  â””â”€â”€ stage
        â”‚Â Â      â”œâ”€â”€ backend.tf
        â”‚Â Â      â”œâ”€â”€ main.tf
        â”‚Â Â      â”œâ”€â”€ outputs.tf
        â”‚Â Â      â””â”€â”€ variables.tf
        â”œâ”€â”€ global
        â”‚Â Â  â”œâ”€â”€ providers.tf
        â”‚Â Â  â””â”€â”€ variables.tf
        â””â”€â”€ modules
            â”œâ”€â”€ alb
            â”‚Â Â  â”œâ”€â”€ main.tf
            â”‚Â Â  â”œâ”€â”€ outputs.tf
            â”‚Â Â  â””â”€â”€ variables.tf
            â”œâ”€â”€ ecs
            â”‚Â Â  â”œâ”€â”€ main.tf
            â”‚Â Â  â”œâ”€â”€ outputs.tf
            â”‚Â Â  â””â”€â”€ variables.tf
            â”œâ”€â”€ iam
            â”‚Â Â  â”œâ”€â”€ ecs_task_policy.json
            â”‚Â Â  â”œâ”€â”€ main.tf
            â”‚Â Â  â”œâ”€â”€ outputs.tf
            â”‚Â Â  â””â”€â”€ variables.tf
            â”œâ”€â”€ updatedeploy
            â”‚Â Â  â”œâ”€â”€ lambda_function.py
            â”‚Â Â  â”œâ”€â”€ lambda.zip
            â”‚Â Â  â”œâ”€â”€ main.tf
            â”‚Â Â  â”œâ”€â”€ outputs.tf
            â”‚Â Â  â””â”€â”€ variables.tf
            â””â”€â”€ vpc
                â”œâ”€â”€ main.tf
                â”œâ”€â”€ outputs.tf
                â””â”€â”€ variables.tf
```

### 2. DescripciÃ³n de directorios

Se tiene la siguiente distribuciÃ³n de archivos y carpetas:
- **app1**: Contiene los archivos necesarios para la contenerizaciÃ³n de la aplicaciÃ³n ``APP1`` propocionada en un repositorio de GitHub.
  - Repositorio Proporcionado APP1: ``https://github.com/G97-TECH-MKT/simple-app1``
  - Repositorio Proporcionado APP2: ``https://github.com/G97-TECH-MKT/simple-app2``
- **app2**: Contiene los archivos necesarios para la contenerizaciÃ³n de la aplicaciÃ³n ``APP2`` propocionada en un repositorio de GitHub.
- **Terraform**: Contiene los mÃ³dulos que serÃ¡n utilizados para poder desplegar la infraestructura.
    - **environments**: Contiene los ambientes para los cuales se desplegarÃ¡ la infraestructura
---

## ğŸš€ EjecuciÃ³n del Proyecto

### âš™ï¸ Requisitos Previos
1. Tener habilitado lo siguiente:
   - Tener una cuenta de GitHub.
   - Consola con git instalado para ingresar comandos.

2. Realizar un Fork a este repositorio:
    - Se deberÃ¡ hacer clic en la secciÃ³n que se llama ``Fork``.
  ![Fork](./images/Fork.png)
    - Seguir los pasos para realizar la operaciÃ³n de Fork.
      - Colocar una descripciÃ³n
      - Quitarle el aspa a "Copy the ``Dev`` branch only"
  ![Fork](./images/Fork1.png)
    - Se crearÃ¡ un repositorio en nuestra cuenta con el nombre del repositorio del cual hicimos fork.

3. Clonar el repositorio:
   ```bash
   git clone https://github.com/<Tu_cuenta>/retoTecnico.git
   cd retoTecnico
   ```
### ğŸ’¡ ExplicaciÃ³n de los flujos
1. **Crear infraestructura previa**:
    - Para este paso debemos ejecutar el flujo ``Crear Infraestructura Previa``, este flujo nos permitirÃ¡ crear los siguientes componentes:
        - **Bucket de S3**: Nos servirÃ¡ para almacenar el archivo ``tfstate``.
        - **Tabla en DynamoDB**: Nos servirÃ¡ para gestionar el estado de la infraestructura gestionada por Terraform.
        - **Repositorios en ECR**: Nos permitirÃ¡ alojar la ``APP1`` y ``APP2`` para luego desplegarlas.
    - **``Este paso tiene como finalidad ejecutarse una sola vez.``**
2. **Dockerizar apps y subirlas al repositorio**:
    - Para este paso debemos ejecutar el flujo ``Build and Push to ECR``, este flujo nos permitirÃ¡ contenerizar y publicar las imagenes de la APP1 y APP2 las veces que deseemos para que en pasos posteriores puedan ser desplegadas.
    - Este paso tiene como finlidad ejecutarse multiples veces.

3. **Desplegar infraestructura**:
    - Para este paso debemos ejecutar el flujo ``Despliegue o DestrucciÃ³n de Infraestructura``, este flujo nos permitirÃ¡ desplegar la infraestructura necesaria para poder ejecutar la imagen previamente publicada en el respectivo repositorio en el paso anterior.
    - Este paso tiene como finlidad ejecutarse multiples veces, ya sea para **desplegar** la infraestructura o **destruirla**.
    

### ğŸƒ Pasos para la EjecuciÃ³n
1. **Configurar secretos**:
    - Debemos crear los respectivos secrets de nuestro proyecto, para lo cual nos dirigimos a ``Settings > Secrets and variables > Actions`` y dar clic en ``New Repository Secret``.
    ![Steps_secrets](./images/Steps_secrets.png)
    - Los secrets que debemos configurar son los siguientes:
        - **AWS_ACCESS_KEY_ID**: *Access key de tu cuenta de aws*
        - **AWS_REGION**: <ins>us-west-1</ins>
        - **AWS_SECRET_ACCESS_KEY**: *Secret key de tu cuenta de aws* 
        - **ECR_REGISTRY**: *Esta variable la podemos obtener luego de ejecutar el flujo*
        - **TF_DYNAMODB_TABLE**: <ins>terraform-lock-table</ins>
        - **TF_S3_BUCKET**: *El nombre del bucket debe ser Ãºnico a nivel global en AWS. Si eliges un nombre ya existente, la creaciÃ³n del bucket fallarÃ¡. AsegÃºrate de usar una convenciÃ³n de nombres que garantice unicidad, como incluir identificadores especÃ­ficos de tu proyecto u organizaciÃ³n.*
        - **TF_S3_KEY**: <ins>infra.tfstate</ins>
    - Los unicos valores que te pido que deben mantenerse son los de ``AWS_REGION`` ``TF_DYNAMODB_TABLE`` ``TF_S3_KEY`` los demÃ¡s pueden variar dependiendo de la cuenta de **AWS** que uses.

    ![Steps_secrets](./images/Secrets.png)

    Como te comentÃ© arriba, la variable ``ECR_REGISTRY`` la generaremos luego de ejecutar el primer workflow.

2. **Ubicarnos en Actions**:
    - Procedemos a activar la secciÃ³n ``Actions``.
    - Nos dirigimos a ``Actions`` y damos clic en el boton verde cuyo nombre es ``I understand my workflows, go ahead and enable them``.

    ![activarWorkflow](./images/ActivarWorkflow.png)
  
    - Debemos dirigirnos a ``Actions `` y ahÃ­ podremos visualizar los flujos que tenemos disponibles:

    ![view_workflows](./images/View_workflows.png)

    - Los flujos que tenemos son los siguiente:
            
        1. Crear Infraestructura Previa
        2. Build and Push to ECR
        3. Despliegue o DestrucciÃ³n de Infraestructura - Dev
        4. Despliegue o DestrucciÃ³n de Infraestructura - Stage
    - Estos flujos se deben ejecutar en el mismo orden que estÃ¡n enumerados, cada vez que demos clic en alguno podemos visualizar un botÃ³n con el nombre ``Run workflow`` el cual al darle clic nos pedirÃ¡ que seleccionemos la rama deseada.
    - Con respecto a las ramas:
        - La rama ``main``: Contiene todo el proyecto
        - La rama ``dev``: Contiene todo el proyecto y es la rama en la cual se deben hacer cambios en las apps
        - La rama ``deploy_iac``: Contiene todo el proyecto y es la rama que despliega toda la infraestructura para realizar el despliegue.
3. **Desplegar infraestructura previa**:
- Una vez configuradas las variables y ubicados los workflows debemos ejecutar el primer flujo para crear los componentes necesarios para que nuestro proyecto funcione.
- Debemos dar clic en ``Actions > Crear Infraestructura Previa > Run workflow > Branch:main`` y dar clic en ``Run Workflow``.
![infra_previa](./images/Infra_previa.png)
- Esto crearÃ¡ los componentes necesarios en **S3**, **DynamoDB** y **ECR**.
- Actualizamos la pagina para ver el proceso.
![infra_previa](./images/Proc_crear_infra_previa.png)
- Una vez culminado se verÃ¡ de la siguiente manera:
![alt text](./images/Success_crear_infra_previa.png)
- Si deseamos podemos ingresar para revisar los logs.
- Este workflow nos permitiÃ³ crear los componentes indicados:
![alt text](./images/Resultado_preinfra.png)
- Recuerda que los Repositorios de ECR y la Tabla de DynamoDB se encuentran en la regiÃ³n que especificamos en las wariables, en este caso ``us-west-1``.
- Con los repositorios de ECR creados ahora si podemos configurar nuestro ultimo secreto  en ``Settings > Secrets and variables > Actions``, recuerda que el secreto que nos faltaba era ``ECR_REGISTRY``.
![new_secret](./images/New_secret.png)
- El valor de ``ECR_REGISTRY`` lo puedes encontrar en **AWS ECR**, en los repositorios que se crearon con el workflow, es la cadena de nÃºmeros que termina en **amazonaws.com**.
![uri](./images/Uri.png)
- Finalmente tenemos todos los secrets necesarios para nuestro proyecto:
![secrets1](./images/Secrets1.png)

4. **Dockerizar apps y subirlas al repositorio**:
- Debemos dar clic en ``Actions > Build and Push to ECR > Run workflow > Branch:dev`` y dar clic en Run Workflow.
![buildandpush](./images/Buildandpush.png)
- Esperemos a que termine el workflow
![statusbuildandpush](./images/Status_buildandpush.png)
- Este workflow se encargarÃ¡ de contenerizar y subir las aplicaciones que nos proporcionaron en los remositorios mencionados al principio a los repositorios creados:
![imagerepo](./images/Imagerepo.png)
- Este flujo se puede ejecutar las veces que deseemos subiendo cambios nuevos de las apps, estÃ¡ configurado para siempre tener una imagen Latest y mantener las versiones anteriores.

5. **Desplegar infraestructura**:
- Debemos dar clic en ``Actions > Crear Infraestructura Previa - Dev > Run workflow > Branch:deploy_iac`` y dar clic en Run Workflow.
![deployInfra](./images/Despliegue_infra.png)
- Una vez ejecutado podemos ingresar al workflow para revisar el proceso:
![deployInfra2](./images/Despliegue_infra2.png)
- Una vez finalizado podemos observar que nos proporciona el DNS del Application load Balancer.
![deployInfra1](./images/Despliegue_infra1.png)
- Por razones de seguridad Github oculta estos datos por los cual debemos buscar este valor en la consola de AWS.
- Debemos dirigirnos al servicio ``EC2`` en AWS y luego ubicarnos en ``Balanceadores de carga``, ahÃ­ podremos extraer el ``DNS``.
![ALB](./images/ALB.png)
- Ahora podemos consultar esa URL en un navegador, debido a la falta de tiempo no pude configurar ``CloudFront`` y ``Certificate Manager`` para poder acceder de forma segura, por lo tanto tendremos que ingresar via **HTTP**.
- Podemos consultar la URL via curl desde la terminal.
    ```bash
    curl dev-alb-1797972737.us-west-1.elb.amazonaws.com
    ```
- Tambien podemos consultar desde el navegador web usando ``HTTP``.
![Response](./images/Response.png)

- DeberÃ­amos obtener lo siguiente:
![Response1](./images/Response2.png)

- De esta manera finalizamos la prueba.
- Recuerda que puedes ejecutar las veces que quieras el workflow ```Build and Push to ECR``` cambiando previamente el contenido del archivo [main](./app1/main.py) para que puedas notar los cambios.
![Evidencia](./images/Evidencia.png)

6. **Eliminar infraestructura**:
- Para poder eliminar la infraestructura basatarÃ¡ con modificar la variable de entorno ``DESTROY_INFRA: False`` a ``True`` del archivo [deploy-IaC-dev.yaml](.github/workflows/deploy-IaC-dev.yml), luego se deberÃ¡ realizar PUSH al repositorio y seguidamente ejecutar el workflow  ``Despliegue o DestrucciÃ³n de Infraestructura - Dev``.

# ğŸ“‹ DocumentaciÃ³n de configuraciÃ³n en Terraform

# DocumentaciÃ³n del Archivo `main.tf` - ConfiguraciÃ³n de VPC

Este archivo define los recursos necesarios para implementar una VPC con subredes pÃºblicas y privadas, un gateway NAT e internet gateway. EstÃ¡ diseÃ±ado para entornos escalables y seguros.

---

## **1. CreaciÃ³n de la VPC**

### Recurso: `aws_vpc.this`
- **DescripciÃ³n:** Crea una VPC con el bloque CIDR especificado.
- **ConfiguraciÃ³n Clave:**
  - **CIDR:** Se define en la variable `var.cidr`.
  - **Etiquetas:** Asigna un nombre basado en el entorno (`${var.environment}-vpc`).

---

## **2. Subredes PÃºblicas**

### Recurso: `aws_subnet.public`
- **DescripciÃ³n:** Crea subredes pÃºblicas dentro de la VPC.
- **ConfiguraciÃ³n Clave:**
  - **Cantidad:** Determinada por la longitud de `var.public_subnets`.
  - **CIDR:** Cada subred utiliza los valores en `var.public_subnets`.
  - **Zona de Disponibilidad:** Definida en `var.availability_zones`.
  - **IP PÃºblica:** Habilitada con `map_public_ip_on_launch = true`.
  - **Etiquetas:** Nombres en el formato `${var.environment}-public-subnet-{index}`.

---

## **3. Subredes Privadas**

### Recurso: `aws_subnet.private`
- **DescripciÃ³n:** Crea subredes privadas dentro de la VPC.
- **ConfiguraciÃ³n Clave:**
  - **Cantidad:** Determinada por la longitud de `var.private_subnets`.
  - **CIDR:** Utiliza los valores en `var.private_subnets`.
  - **Zona de Disponibilidad:** Configurada con `var.availability_zones`.
  - **Etiquetas:** Nombres en el formato `${var.environment}-private-subnet-{index}`.

---

## **4. Internet Gateway**

### Recurso: `aws_internet_gateway.this`
- **DescripciÃ³n:** Permite que las subredes pÃºblicas tengan acceso a internet.
- **ConfiguraciÃ³n Clave:**
  - **VPC Asociada:** La VPC creada en `aws_vpc.this`.
  - **Etiquetas:** Nombre en el formato `${var.environment}-internet-gateway`.

---

## **5. Tabla de Rutas PÃºblicas**

### Recurso: `aws_route_table.public`
- **DescripciÃ³n:** Configura una tabla de rutas para las subredes pÃºblicas.
- **ConfiguraciÃ³n Clave:**
  - **VPC Asociada:** `aws_vpc.this`.
  - **Ruta por Defecto:**
    - **Destino:** `0.0.0.0/0` (todo el trÃ¡fico externo).
    - **Gateway:** `aws_internet_gateway.this.id`.
  - **Etiquetas:** Nombre en el formato `${var.environment}-public-route-table`.

### AsociaciÃ³n de Tabla de Rutas
- **Recurso:** `aws_route_table_association.public`
- **DescripciÃ³n:** Asocia la tabla de rutas pÃºblicas con cada subred pÃºblica.

---

## **6. NAT Gateway**

### Recurso: `aws_nat_gateway.this`
- **DescripciÃ³n:** Permite que las subredes privadas accedan a internet para tareas como actualizaciones de paquetes.
- **ConfiguraciÃ³n Clave:**
  - **Elastic IP:** Asignado mediante `aws_eip.nat.id`.
  - **Subred:** Implementado en la primera subred pÃºblica (`aws_subnet.public[0]`).
  - **Etiquetas:** Nombre en el formato `${var.environment}-nat-gateway`.

---

## **7. Elastic IP para NAT**

### Recurso: `aws_eip.nat`
- **DescripciÃ³n:** Proporciona una direcciÃ³n IP estÃ¡tica para el NAT Gateway.
- **ConfiguraciÃ³n Clave:**
  - **Dependencia:** Creado despuÃ©s del Internet Gateway (`depends_on = [aws_internet_gateway.this]`).

---

## **8. Tabla de Rutas Privadas**

### Recurso: `aws_route_table.private`
- **DescripciÃ³n:** Configura una tabla de rutas para las subredes privadas.
- **ConfiguraciÃ³n Clave:**
  - **VPC Asociada:** `aws_vpc.this`.
  - **Ruta por Defecto:**
    - **Destino:** `0.0.0.0/0`.
    - **Gateway NAT:** `aws_nat_gateway.this.id`.
  - **Etiquetas:** Nombre en el formato `${var.environment}-private-route-table`.

### AsociaciÃ³n de Tabla de Rutas
- **Recurso:** `aws_route_table_association.private`
- **DescripciÃ³n:** Asocia la tabla de rutas privadas con cada subred privada.

---

# Resumen
Este archivo implementa:
1. Una **VPC** con subredes pÃºblicas y privadas.
2. Un **Internet Gateway** para las subredes pÃºblicas.
3. Un **NAT Gateway** para proporcionar conectividad a internet desde subredes privadas.
4. Tablas de rutas pÃºblicas y privadas para gestionar el flujo de trÃ¡fico.

Esta configuraciÃ³n es Ãºtil para arquitecturas donde las instancias en subredes privadas necesitan acceso a internet sin ser accesibles directamente desde el exterior.


# DocumentaciÃ³n del Archivo `main.tf` - ConfiguraciÃ³n de IAM

Este archivo define roles y polÃ­ticas IAM necesarios para habilitar la ejecuciÃ³n de tareas ECS. A continuaciÃ³n, se explica cada recurso configurado.

---

## **1. Rol de EjecuciÃ³n para ECS**

### Recurso: `aws_iam_role.ecs_execution`
- **DescripciÃ³n:** Crea un rol que serÃ¡ asumido por tareas ECS para acceder a servicios de AWS como ECR y CloudWatch.
- **ConfiguraciÃ³n Clave:**
  - **Nombre:** `${var.environment}-ecs-execution-role` (incluye el entorno).
  - **PolÃ­tica de AsunciÃ³n:** Permite que el servicio `ecs-tasks.amazonaws.com` asuma este rol.
  - **Ejemplo de PolÃ­tica:**
    ```json
    {
      "Version": "2012-10-17",
      "Statement": [
        {
          "Effect": "Allow",
          "Principal": { "Service": "ecs-tasks.amazonaws.com" },
          "Action": "sts:AssumeRole"
        }
      ]
    }
    ```

---

## **2. Adjuntar PolÃ­tica Administrada al Rol de EjecuciÃ³n**

### Recurso: `aws_iam_role_policy_attachment.ecs_execution_policy`
- **DescripciÃ³n:** Vincula la polÃ­tica administrada de AWS `AmazonECSTaskExecutionRolePolicy` al rol de ejecuciÃ³n para permitir:
  - Recuperar imÃ¡genes desde ECR.
  - Registrar logs en CloudWatch.
- **ConfiguraciÃ³n Clave:**
  - **Policy ARN:** `arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy`.

---

## **3. PolÃ­tica en LÃ­nea para el Rol de EjecuciÃ³n**

### Recurso: `aws_iam_role_policy.ecs_execution_policy_inline`
- **DescripciÃ³n:** Define permisos adicionales para que las tareas ECS puedan crear grupos de logs en CloudWatch.
- **ConfiguraciÃ³n Clave:**
  - **Nombre:** `${var.environment}-ecs-execution-policy-inline`.
  - **AcciÃ³n Permitida:** `logs:CreateLogGroup`.
  - **Recursos Permitidos:** `arn:aws:logs:*:*:*` (todos los grupos de logs).

---

## **4. Rol para las Tareas de ECS**

### Recurso: `aws_iam_role.ecs_task`
- **DescripciÃ³n:** Crea un rol asumido por las tareas ECS para ejecutar contenedores con permisos personalizados.
- **ConfiguraciÃ³n Clave:**
  - **Nombre:** `${var.environment}-ecs-task-role`.
  - **PolÃ­tica de AsunciÃ³n:** Permite que `ecs-tasks.amazonaws.com` asuma este rol.
  - **Ejemplo de PolÃ­tica:**
    ```json
    {
      "Version": "2012-10-17",
      "Statement": [
        {
          "Effect": "Allow",
          "Principal": { "Service": "ecs-tasks.amazonaws.com" },
          "Action": "sts:AssumeRole"
        }
      ]
    }
    ```

---

## **5. Adjuntar PolÃ­tica Administrada al Rol de Tareas**

### Recurso: `aws_iam_role_policy_attachment.ecs_task_policy_attachment`
- **DescripciÃ³n:** Vincula la polÃ­tica administrada de AWS `AmazonECSTaskExecutionRolePolicy` al rol de tareas ECS, otorgando permisos generales para la ejecuciÃ³n de contenedores.

---

## **6. PolÃ­tica en LÃ­nea para las Tareas de ECS**

### Recurso: `aws_iam_role_policy.ecs_task_policy`
- **DescripciÃ³n:** Adjunta una polÃ­tica personalizada al rol de tareas ECS. 
- **ConfiguraciÃ³n Clave:**
  - **Nombre:** `${var.environment}-ecs-task-policy`.
  - **PolÃ­tica:** Definida en un archivo externo (`ecs_task_policy.json`), que incluye permisos especÃ­ficos para la lÃ³gica de la aplicaciÃ³n.

---

# Resumen
Este archivo configura los elementos necesarios para que ECS interactÃºe con los recursos de AWS:
1. **Rol de EjecuciÃ³n (`ecs_execution`):** Habilita la interacciÃ³n con ECR y CloudWatch.
2. **Rol de Tareas (`ecs_task`):** Proporciona permisos personalizados para ejecutar tareas ECS.
3. **PolÃ­ticas Administradas y En LÃ­nea:** Combina permisos estÃ¡ndar y especÃ­ficos para cada ambiente.

---

# DocumentaciÃ³n del Archivo `main.tf` - ConfiguraciÃ³n de ECS


Este archivo `main.tf` configura un clÃºster de **AWS ECS** utilizando Fargate para desplegar dos aplicaciones (`app1` y `app2`). A continuaciÃ³n, se describe cada componente en detalle.

---

## **1. ClÃºster de ECS**
Se crea un clÃºster ECS para alojar las tareas:

```hcl
resource "aws_ecs_cluster" "this" {
  name = "${var.environment}-ecs-cluster"
}
```
## **2. Definiciones de Tarea (Task Definitions)**
Se definen las tareas de ECS para cada aplicaciÃ³n. Las tareas incluyen configuraciÃ³n del contenedor, red, y monitoreo.

#### **Tarea de `app1`**

```hcl
resource "aws_ecs_task_definition" "app1" {
  family                   = "${var.environment}-${var.app1_image}-task"
  network_mode             = "awsvpc"
  requires_compatibilities = ["FARGATE"]
  cpu                      = "1024"
  memory                   = "3072"
  execution_role_arn       = var.execution_role_arn
  task_role_arn            = var.task_role_arn

  runtime_platform {
    operating_system_family = "LINUX"
    cpu_architecture        = "X86_64"
  }

  container_definitions = jsonencode([
    {
      name      = var.app1_image
      image     = "${var.repositorio_ecr}/${var.app1_image}:${var.image_tag}"
      essential = true
      portMappings = [
        {
          name          = "${var.app1_image}-8000-tcp"
          containerPort = 8000
          hostPort      = 8000
          protocol      = "tcp"
          appProtocol   = "http"
        }
      ]
      environment = [
        {
          name  = "ENV"
          value = var.environment
        }
      ]
      logConfiguration = {
        logDriver = "awslogs"
        options = {
          "awslogs-group"         = "/ecs/${var.environment}-${var.app1_image}"
          "awslogs-region"        = var.aws_region
          "awslogs-create-group"  = "true"
          "awslogs-stream-prefix" = "ecs"
          "mode"                  = "non-blocking"
          "max-buffer-size"       = "25m"
        }
      }
    }
  ])
}
```
#### **Tarea de `app2`**
```hcl
resource "aws_ecs_task_definition" "app2" {
  family                   = "${var.environment}-${var.app2_image}-task"
  network_mode             = "awsvpc"
  requires_compatibilities = ["FARGATE"]
  cpu                      = "1024"
  memory                   = "2048"
  execution_role_arn       = var.execution_role_arn
  task_role_arn            = var.task_role_arn

  runtime_platform {
    operating_system_family = "LINUX"
    cpu_architecture        = "X86_64"
  }

  container_definitions = jsonencode([
    {
      name      = var.app2_image
      image     = "${var.repositorio_ecr}/${var.app2_image}:${var.image_tag}"
      portMappings = [
        {
          name          = "${var.app2_image}-8000-tcp"
          containerPort = 8000
          hostPort      = 8000
          protocol      = "tcp"
          appProtocol   = "http"
        }
      ]
      environment = [
        {
          name  = "ENV"
          value = var.environment
        }
      ]
      logConfiguration = {
        logDriver = "awslogs"
        options = {
          "awslogs-group"         = "/ecs/${var.environment}-${var.app2_image}"
          "awslogs-region"        = var.aws_region
          "awslogs-create-group"  = "true"
          "awslogs-stream-prefix" = "ecs"
          "mode"                  = "non-blocking"
          "max-buffer-size"       = "25m"
        }
      }
    }
  ])
}
```

## **3. Servicios ECS (ECS Services)**
Cada aplicaciÃ³n se configura como un servicio ECS para asegurar la disponibilidad y administraciÃ³n del ciclo de vida.

#### **Servicio de `app1`**

```hcl
resource "aws_ecs_service" "app1" {
  name            = "${var.environment}-${var.app1_image}-service"
  cluster         = aws_ecs_cluster.this.id
  task_definition = aws_ecs_task_definition.app1.arn
  desired_count   = var.desired_count
  launch_type     = "FARGATE"

  network_configuration {
    subnets         = var.subnets
    security_groups = [var.security_group_id]
    assign_public_ip = false
  }

  load_balancer {
    target_group_arn = var.app1_target_group_arn
    container_name   = var.app1_image
    container_port   = 8000
  }
}
```

#### **Servicio de `app2`**

```hcl
resource "aws_ecs_service" "app2" {
  name            = "${var.environment}-${var.app2_image}-service"
  cluster         = aws_ecs_cluster.this.id
  task_definition = aws_ecs_task_definition.app2.arn
  desired_count   = var.desired_count
  launch_type     = "FARGATE"

  network_configuration {
    subnets         = var.subnets
    security_groups = [var.security_group_id]
    assign_public_ip = false
  }

  load_balancer {
    target_group_arn = var.app2_target_group_arn
    container_name   = var.app2_image
    container_port   = 8000
  }
}
```
# Resumen
Este archivo implementa:
1. Un **clÃºster de ECS** para ejecutar las tareas.
2. Define las **tareas ECS** para `app1` y `app2` con sus configuraciones especÃ­ficas:
   - Recursos como CPU, memoria y roles de ejecuciÃ³n.
   - Definiciones del contenedor, incluyendo puertos, variables de entorno y configuraciÃ³n de logs.
3. Configura los **servicios ECS** para `app1` y `app2`, asegurando alta disponibilidad y conectividad con subredes y balanceadores de carga.

# DocumentaciÃ³n del Archivo `main.tf` - ConfiguraciÃ³n de ALB

Este archivo `main.tf` configura un **Application Load Balancer (ALB)** en AWS para enrutar el trÃ¡fico hacia dos aplicaciones (`app1` y `app2`) utilizando Terraform. A continuaciÃ³n, se describen los recursos creados.

---
## 1. Application Load Balancer (ALB)
Se crea un ALB que distribuye trÃ¡fico hacia las aplicaciones configuradas.

```hcl
resource "aws_lb" "this" {
  name               = "${var.environment}-alb"
  internal           = false
  load_balancer_type = "application"
  security_groups    = [var.security_group_id]
  subnets            = var.subnets

  enable_deletion_protection = false

  tags = {
    Environment = var.environment
  }
}
```
## 2. Grupos de Destino (Target Groups)

**Grupo de destino para ```app1```**
- Define el puerto, protocolo y verificaciones de salud especÃ­ficas para la primera aplicaciÃ³n.
```hcl
resource "aws_lb_target_group" "app1" {
  name        = "${var.environment}-${var.app1_image}-tg"
  port        = 8000
  protocol    = "HTTP"
  vpc_id      = var.vpc_id
  target_type = "ip"

  health_check {
    path                = "/"
    interval            = 30
    timeout             = 5
    healthy_threshold   = 5
    unhealthy_threshold = 2
    matcher             = "200-299"
  }

  tags = {
    Environment = var.environment
  }
}
```
**Grupo de destino para ```app2```**
- Similar al grupo de destino de app1, pero con configuraciÃ³n especÃ­fica para la segunda aplicaciÃ³n.
```hcl
resource "aws_lb_target_group" "app2" {
  name        = "${var.environment}-${var.app2_image}-tg"
  port        = 8000
  protocol    = "HTTP"
  vpc_id      = var.vpc_id
  target_type = "ip"

  health_check {
    path                = "/"
    interval            = 30
    timeout             = 5
    healthy_threshold   = 5
    unhealthy_threshold = 2
    matcher             = "200-299"
  }

  tags = {
    Environment = var.environment
  }
}
```

## 3. Listeners
Se configuran listeners para enrutar el trÃ¡fico HTTP a los grupos de destino.

**Listener para ```app1```**
- Enruta trÃ¡fico HTTP en el puerto 80 hacia el grupo de destino de app1.
```hcl
resource "aws_lb_listener" "http-app1" {
  load_balancer_arn = aws_lb.this.arn
  port              = "80"
  protocol          = "HTTP"

  default_action {
    type             = "forward"
    target_group_arn = aws_lb_target_group.app1.arn
  }
}

```
**Listener para ```app2```**
- Enruta trÃ¡fico HTTP en el puerto 8080 hacia el grupo de destino de app2.
```hcl
resource "aws_lb_listener" "http-app2" {
  load_balancer_arn = aws_lb.this.arn
  port              = "8080"
  protocol          = "HTTP"

  default_action {
    type             = "forward"
    target_group_arn = aws_lb_target_group.app2.arn
  }
}
```
---
# **Resumen**
Este script de Terraform realiza las siguientes configuraciones principales:

1. Crea un **Application Load Balancer** con seguridad y configuraciÃ³n especÃ­ficas.
2. Define **grupos de destino (Target Groups)** para las aplicaciones:
   - ConfiguraciÃ³n de los puertos, protocolos y verificaciones de salud.
3. Configura **listeners** que enrutan trÃ¡fico HTTP a los grupos de destino correspondientes.

---

# ğŸ“‹ DocumentaciÃ³n del Archivo `main.tf` - ActualizaciÃ³n de Despliegues con Lambda y ECS

Este archivo define los recursos necesarios para implementar una funciÃ³n Lambda que actualiza servicios ECS al recibir eventos de push en ECR. EstÃ¡ diseÃ±ado para ser escalable, eficiente y automatizado.

---

## **1. Roles y PolÃ­ticas de IAM**

### Recurso: `aws_iam_role.lambda_role`
- **DescripciÃ³n:** Rol IAM que permite a Lambda asumir permisos necesarios.
- **ConfiguraciÃ³n Clave:**
  - **PolÃ­tica de AsunciÃ³n:** Permite que `lambda.amazonaws.com` asuma este rol.
  - **Etiquetas:** Nombre del rol basado en el entorno (`lambda-role-${var.environment}`).

### Recurso: `aws_iam_role_policy_attachment.lambda_policy_attachment`
- **DescripciÃ³n:** Adjunta la polÃ­tica bÃ¡sica de ejecuciÃ³n para Lambda.
- **ConfiguraciÃ³n Clave:**
  - **PolÃ­tica:** `AWSLambdaBasicExecutionRole`.

### Recurso: `aws_iam_policy.ecs_permissions`
- **DescripciÃ³n:** PolÃ­tica personalizada que otorga permisos para interactuar con ECS.
- **ConfiguraciÃ³n Clave:**
  - **Permisos Incluidos:**
    - `ecs:RegisterTaskDefinition`
    - `ecs:UpdateService`
    - `ecs:DescribeServices`
    - `ecs:DescribeClusters`
    - `ecs:ListServices`
    - `iam:PassRole`
  - **Alcance:** Aplicado a todos los recursos (`Resource = ["*"]`).

### Recurso: `aws_iam_role_policy_attachment.ecs_policy_attachment`
- **DescripciÃ³n:** Adjunta la polÃ­tica personalizada a la funciÃ³n Lambda.
- **ConfiguraciÃ³n Clave:**
  - **Rol Asociado:** `lambda-role-${var.environment}`.

---

## **2. FunciÃ³n Lambda**

### Recurso: `aws_lambda_function.update_deploy_lambda`
- **DescripciÃ³n:** FunciÃ³n Lambda que actualiza los servicios ECS tras un evento de push en ECR.
- **ConfiguraciÃ³n Clave:**
  - **Nombre:** `update-deploy-${var.environment}`.
  - **Rol Asociado:** `lambda-role-${var.environment}`.
  - **CÃ³digo Fuente:** `lambda.zip` ubicado en el directorio del mÃ³dulo.
  - **Variables de Entorno:**
    - `ECS_CLUSTER`
    - `ENVIRONMENT`
    - `EXECUTION_ROLE`
    - `TASK_ROLE`
    - `REPOSITORIO_ECR`
  - **Etiquetas:** Nombre con el formato `update-deploy-${var.environment}`.

---

## **3. Regla de CloudWatch para Disparadores**

### Recurso: `aws_cloudwatch_event_rule.ecr_push_rule`
- **DescripciÃ³n:** Configura un disparador basado en eventos de push en repositorios ECR.
- **ConfiguraciÃ³n Clave:**
  - **Evento:** `ECR Image Action` con acciÃ³n de tipo `PUSH` y resultado `SUCCESS`.
  - **Filtros Personalizados:**
    - Repositorios: `${var.app1_image}`, `${var.app2_image}`.
    - Etiqueta de Imagen: `${var.image_tag}`.

### Recurso: `aws_cloudwatch_event_target.ecr_push_lambda_target`
- **DescripciÃ³n:** Asocia la regla de CloudWatch con la funciÃ³n Lambda.
- **ConfiguraciÃ³n Clave:**
  - **Regla:** `ecr-push-rule-${var.environment}`.
  - **Destino:** ARN de la funciÃ³n Lambda.

---

## **4. Permiso para Lambda desde EventBridge**

### Recurso: `aws_lambda_permission.allow_eventbridge`
- **DescripciÃ³n:** Permite a EventBridge invocar la funciÃ³n Lambda.
- **ConfiguraciÃ³n Clave:**
  - **Principal:** `events.amazonaws.com`.
  - **ARN de la Fuente:** Regla de CloudWatch `ecr-push-rule-${var.environment}`.

---

## **5. Datos de Identidad del Llamador**

### Data Source: `aws_caller_identity.current`
- **DescripciÃ³n:** Obtiene informaciÃ³n sobre la cuenta de AWS actual para su uso en configuraciones adicionales.

---

# Resumen

Este archivo implementa:
1. Un **rol IAM** y polÃ­ticas necesarias para la ejecuciÃ³n de Lambda y la interacciÃ³n con ECS.
2. Una **funciÃ³n Lambda** que actualiza servicios ECS tras eventos de push en ECR.
3. ConfiguraciÃ³n de **reglas de CloudWatch** para desencadenar la funciÃ³n Lambda.
4. Permisos explÃ­citos para que EventBridge invoque la funciÃ³n Lambda.

Esta configuraciÃ³n automatiza los despliegues en ECS, asegurando un flujo continuo desde la construcciÃ³n de imÃ¡genes en ECR hasta la actualizaciÃ³n de servicios en ECS.

**De esta manera finalizamos el desarrollo del reto tÃ©cnico.**

## Authors

- [@JesquivelR](https://www.github.com/JesquivelR)